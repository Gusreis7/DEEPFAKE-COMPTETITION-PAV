{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch import nn\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import torchaudio\n",
    "import librosa\n",
    "import tqdm\n",
    "from torchaudio import transforms\n",
    "from torch.utils.data import DataLoader, Dataset,TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "DEVICE = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {DEVICE} device\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data_dir, is_label, TARGET_SAMPLE_RATE = 16000):\n",
    "        #is label = True para audios com label, False para audios sem label, isso garante que mudanças no pipeline de extração de features sejam para ambos os conjuntos\n",
    "        self.data_dir = data_dir\n",
    "        self.classes = [\"real\", \"fake\"]\n",
    "        self.audio_files = []\n",
    "        self.labels = []\n",
    "        self.is_label = is_label\n",
    "        self.TARGET_SAMPLE_RATE =TARGET_SAMPLE_RATE\n",
    "        if self.is_label:\n",
    "            for class_idx, class_name in enumerate(self.classes):\n",
    "                class_dir = os.path.join(data_dir, class_name)\n",
    "                for file in os.listdir(class_dir):\n",
    "                    if file.endswith(\".mp3\"):\n",
    "                        self.audio_files.append(os.path.join(class_dir, file))\n",
    "                        self.labels.append(class_idx)\n",
    "        else:            \n",
    "            for file in os.listdir(self.data_dir):\n",
    "                if file.endswith(\".mp3\"):\n",
    "                    self.audio_files.append(os.path.join(self.data_dir,file))\n",
    "\n",
    "        self.mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=TARGET_SAMPLE_RATE, n_fft=1024, hop_length=512, n_mels=64\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_file = self.audio_files[idx]\n",
    "        if self.is_label:\n",
    "            label = self.labels[idx]\n",
    "\n",
    "        # Load audio\n",
    "        audio, sr = torchaudio.load(audio_file)\n",
    "        # Convert to mono\n",
    "        if audio.shape[0] > 1:\n",
    "            audio = torch.mean(audio, dim=0).unsqueeze(0)\n",
    "\n",
    "        if sr != self.TARGET_SAMPLE_RATE:\n",
    "            audio = torchaudio.transforms.Resample(sr, self.TARGET_SAMPLE_RATE)(audio)\n",
    "\n",
    "        # Pad or truncate the audio to a fixed length\n",
    "        fixed_length = (\n",
    "            self.TARGET_SAMPLE_RATE * 3\n",
    "        )  # Adjust this value based on your requirements\n",
    "        if audio.shape[1] < fixed_length:\n",
    "            audio = torch.nn.functional.pad(audio, (0, fixed_length - audio.shape[1]))\n",
    "        else:\n",
    "            audio = audio[:, :fixed_length]\n",
    "\n",
    "        audio = self.mel_spectrogram(audio)\n",
    "        if self.is_label:\n",
    "            return audio, label\n",
    "        else:\n",
    "            #import for test generating\n",
    "            return audio, os.path.basename(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "   \n",
    "    def __init__(self, batch_size,dataset_train,dataset_test, do_split):\n",
    "        self.modes = ['train','test']\n",
    "        self.dataloaders = {}\n",
    "        self.batch_size = batch_size\n",
    "        self.do_split = do_split\n",
    "        if self.do_split:\n",
    "            self.modes = ['train','validation','test']\n",
    "            generator = torch.Generator().manual_seed(42)\n",
    "            train_size = int(len(dataset_train.audio_files)*0.8)\n",
    "            val_size = int(len(dataset_train.audio_files)-train_size)\n",
    "            train_set, val_set = random_split(dataset_train, [train_size, val_size], generator=generator)\n",
    "\n",
    "            self.dataloaders['train'] = train_set\n",
    "            self.dataloaders['validation'] = val_set\n",
    "        else:\n",
    "            self.dataloaders['train'] = dataset_train\n",
    "            \n",
    "        self.dataloaders['test'] = dataset_test\n",
    "    \n",
    "\n",
    "    def get_loader(self, mode):\n",
    "        if mode == 'train':\n",
    "            return  DataLoader(self.dataloaders[mode], batch_size=self.batch_size, shuffle=True)\n",
    "        else:\n",
    "            return  DataLoader(self.dataloaders[mode], batch_size=self.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    \n",
    "    def __init__(self):\n",
    "    \n",
    "        self.loss_fn = nn.BCELoss()\n",
    "    def get_loss(self, y, y_hat):\n",
    "        return self.loss_fn(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, kernel_size=3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        dummy_tensor = self.conv_layer(torch.zeros(self.input_size).unsqueeze(0))\n",
    "        dim = 1\n",
    "        for d in dummy_tensor.shape[1:]:\n",
    "            dim *= d\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    def __init__(self, input_size):\n",
    "        self.model = NeuralNetwork(input_size=input_size)\n",
    "        self.model.to(DEVICE)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def update(self, loss):\n",
    "        # Backpropagation\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics e best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    #FOR TRAIN AND VALIDATION ONLY\n",
    "    def __init__(self):\n",
    "        self.metrics_save = {}\n",
    "        self.best_models_weigths = {}\n",
    "        \n",
    "    def calc_metrics(self,preds,labels,mode,loss, model_weigths=None, show=False):\n",
    "        acc = accuracy_score(y_pred=preds, y_true=labels)\n",
    "        recall = recall_score(y_pred=preds, y_true=labels)\n",
    "        precision = precision_score(y_pred=preds, y_true=labels)\n",
    "        f1 = f1_score(y_pred=preds, y_true=labels,average='binary')\n",
    "        metrics_names = ['acuracy','recall','precision','f1-score']\n",
    "        metrics_values = [acc,recall,precision,f1]\n",
    "\n",
    "\n",
    "        ###################LOSS#############################################\n",
    "        if f'{mode}_loss' not in self.metrics_save.keys():\n",
    "            self.metrics_save[f'{mode}_loss'] = [loss]\n",
    "        else:\n",
    "            self.metrics_save[f'{mode}_loss'].append(loss)\n",
    "        ################################################################\n",
    "        \n",
    "        if show:\n",
    "            print(f\"Acuracy: {acc:.2f} - Recall {recall:.2f} - Precision {precision:.2f} - F1-Score {f1:.2f} - Loss {loss:.2f}\")\n",
    "\n",
    "\n",
    "        #############Metrics##################################################\n",
    "        \n",
    "        for metric_name, metric_value in zip(metrics_names, metrics_values):\n",
    "\n",
    "            ###Add metrics \n",
    "            if f'{mode}_{metric_name}' not in self.metrics_save.keys():\n",
    "                self.metrics_save[f'{mode}_{metric_name}'] = [metric_value]\n",
    "            else:\n",
    "                self.metrics_save[f'{mode}_{metric_name}'].append(metric_value)\n",
    "            \n",
    "            ###Sava best metrics and respective weigths \n",
    "            if mode == 'train':\n",
    "                if f'{mode}_best_{metric_name}' not in self.metrics_save.keys():\n",
    "                    self.metrics_save[f'{mode}_best_{metric_name}'] = metric_value\n",
    "                    self.best_models_weigths[f'{mode}_best_{metric_name}'] = model_weigths\n",
    "                elif metric_value > self.metrics_save[f'{mode}_best_{metric_name}'] :\n",
    "                    self.best_models_weigths[f'{mode}_best_{metric_name}'] = model_weigths\n",
    "    \n",
    "        ################################################################\n",
    "\n",
    "    def get_best_model(self, metric):\n",
    "        for key in self.best_models_weigths.keys():\n",
    "                if metric in key:\n",
    "                    return self.best_models_weigths[key]\n",
    "    \n",
    "    def save_best_model(self,all_metrics, metric='F1-Score'):\n",
    "        if all_metrics:\n",
    "            print(\"Saving all models\")\n",
    "            for key in self.best_models_weigths.keys():\n",
    "                torch.save(f'{self.best_models_weigths[key]}.pt', key)\n",
    "                print(f\"Save model at: {key}.pt\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Saving best model for {metric}\")\n",
    "            for key in self.best_models_weigths.keys():\n",
    "                if metric in key:\n",
    "                    torch.save(f'{self.best_models_weigths[key]}.pt', key)\n",
    "                    print(f\"Save model at: {key}.pt\")\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, data: Data, learner: Learner, evaluator: Evaluator, metrics: Metrics):\n",
    "        self.data = data\n",
    "        self.learner = learner\n",
    "        self.metrics = metrics\n",
    "        self.evaluator = evaluator\n",
    "\n",
    "    def one_epoch(self, mode):\n",
    "        print(mode)\n",
    "        if mode == 'train':\n",
    "            self.learner.model.train(True)\n",
    "        else:\n",
    "            self.learner.model.train(False)\n",
    "    \n",
    "\n",
    "        dataloader = self.data.get_loader(mode)\n",
    "        preds = []\n",
    "        labels = []\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for (X, y) in tqdm.tqdm(dataloader):\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE).float().unsqueeze(1)\n",
    "\n",
    "            y_hat = self.learner.predict(X)\n",
    "            \n",
    "            loss = self.evaluator.get_loss(y, y_hat)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            if mode == 'train':\n",
    "                self.learner.update(loss)\n",
    "\n",
    "            labels.extend(y.int().tolist())\n",
    "            preds.extend((y_hat > 0.5).int().tolist())\n",
    "        \n",
    "        epoch_loss /= len(dataloader)\n",
    "\n",
    "        #preds,labels,mode,loss, model_weigths=None, show=False\n",
    "        self.metrics.calc_metrics(preds=preds, labels=labels, mode=mode, loss=epoch_loss, model_weigths=self.learner.model.state_dict(), show=True)\n",
    "\n",
    "    def test(self,mode,name_test, model_weigths=None):\n",
    "        self.learner.model.load_state_dict(model_weigths)\n",
    "        self.learner.model.train(False)\n",
    "        dataloader = self.data.get_loader(mode)\n",
    "        preds = []\n",
    "        ids = []\n",
    "        for (X, x_id) in tqdm.tqdm(dataloader):\n",
    "            X = X.to(DEVICE)\n",
    "            y_hat = self.learner.predict(X)\n",
    "            ids.extend(x_id)\n",
    "            preds.extend((y_hat).float().tolist())\n",
    "        \n",
    "        file_test_submtion =  open(f'{name_test}.csv','w')\n",
    "        file_test_submtion.write('id,filename,fake_prob\\n')\n",
    "        id_n = 0\n",
    "        for idx,pred in zip(ids,preds):\n",
    "            file_test_submtion.write(f\"{id_n},{idx},{pred[0]}\\n\")\n",
    "            id_n+=1\n",
    "        print(f\"Test submission for {name_test} saved at {name_test}.csv\")\n",
    "\n",
    "\n",
    "    def run(self, n_epochs: int):\n",
    "        print(\"Starting training\")\n",
    "        for t in range(n_epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            self.one_epoch(mode='train')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self.one_epoch(mode='validation')\n",
    "        print(\"Training done\")\n",
    "        \n",
    "    def run_test(self,name_test):\n",
    "        #Keep test at the end of training\n",
    "        metric = 'f1-score'\n",
    "        print(f\"Generating test probs with {metric} best model:\")\n",
    "        with torch.no_grad():\n",
    "            best_model = self.metrics.get_best_model(metric=metric)\n",
    "            self.test(mode='test', name_test=name_test, model_weigths=best_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets\n",
    "audio_train = AudioDataset(data_dir='/home/gustavo/Projects/PAV/DEEPFAKE-COMPTETITION-PAV/audios/train', is_label=True)\n",
    "audio_teste = AudioDataset(data_dir='/home/gustavo/Projects/PAV/DEEPFAKE-COMPTETITION-PAV/audios/test', is_label=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloaders\n",
    "data =Data(batch_size=100, dataset_train=audio_train, dataset_test=audio_teste, do_split=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluator\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner\n",
    "learner = Learner(input_size=(1,64,94))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:17<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.49 - Recall 0.25 - Precision 0.86 - F1-Score 0.39 - Loss 0.67\n",
      "validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:03<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.80 - Recall 0.80 - Precision 0.86 - F1-Score 0.83 - Loss 0.59\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:17<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.84 - Recall 0.91 - Precision 0.86 - F1-Score 0.88 - Loss 0.50\n",
      "validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:03<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.83 - Recall 0.91 - Precision 0.83 - F1-Score 0.87 - Loss 0.48\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:17<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.85 - Recall 0.92 - Precision 0.86 - F1-Score 0.89 - Loss 0.43\n",
      "validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:03<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.84 - Recall 0.91 - Precision 0.85 - F1-Score 0.88 - Loss 0.45\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:18<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.86 - Recall 0.92 - Precision 0.87 - F1-Score 0.89 - Loss 0.40\n",
      "validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:03<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.83 - Recall 0.91 - Precision 0.83 - F1-Score 0.87 - Loss 0.44\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:18<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.86 - Recall 0.92 - Precision 0.87 - F1-Score 0.90 - Loss 0.38\n",
      "validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:03<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.85 - Recall 0.91 - Precision 0.85 - F1-Score 0.88 - Loss 0.42\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:17<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.86 - Recall 0.92 - Precision 0.88 - F1-Score 0.90 - Loss 0.36\n",
      "validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:03<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.84 - Recall 0.92 - Precision 0.84 - F1-Score 0.88 - Loss 0.42\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:17<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.87 - Recall 0.92 - Precision 0.88 - F1-Score 0.90 - Loss 0.35\n",
      "validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:03<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.85 - Recall 0.90 - Precision 0.86 - F1-Score 0.88 - Loss 0.40\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:17<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.87 - Recall 0.92 - Precision 0.88 - F1-Score 0.90 - Loss 0.35\n",
      "validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:04<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.85 - Recall 0.91 - Precision 0.86 - F1-Score 0.88 - Loss 0.39\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:17<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.87 - Recall 0.92 - Precision 0.88 - F1-Score 0.90 - Loss 0.33\n",
      "validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:03<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.85 - Recall 0.90 - Precision 0.86 - F1-Score 0.88 - Loss 0.39\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:17<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.87 - Recall 0.93 - Precision 0.89 - F1-Score 0.91 - Loss 0.32\n",
      "validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:04<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.85 - Recall 0.89 - Precision 0.87 - F1-Score 0.88 - Loss 0.39\n",
      "Training done\n",
      "Generating test probs with f1-score best model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:09<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test submission for test_cnn1 saved at test_cnn1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(data=data, evaluator=evaluator, learner=learner, metrics=metrics)\n",
    "trainer.run(n_epochs=10)\n",
    "trainer.run_test(name_test='test_cnn1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all metrics\n",
    "metrics.save_best_model(all_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save only one metric\n",
    "metrics.save_best_model(all_metrics=False, metric='recall')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
