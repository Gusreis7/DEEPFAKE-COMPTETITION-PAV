{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OsT0iNmSDN2e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tqdm\n",
        "import torch\n",
        "import random\n",
        "import librosa\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchaudio import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.utils.data import DataLoader, Dataset,TensorDataset\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCTwr14UDN2f",
        "outputId": "0966a1e4-d097-4922-dad9-766fdde65f35"
      },
      "outputs": [],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "DEVICE = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {DEVICE} device\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-zsnnj1DN2g"
      },
      "source": [
        "DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b-3HVDWiDN2h"
      },
      "outputs": [],
      "source": [
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, data_dir, is_label, TARGET_SAMPLE_RATE = 16000):\n",
        "        #is label = True para audios com label, False para audios sem label, isso garante que mudanças no pipeline de extração de features sejam para ambos os conjuntos\n",
        "        self.data_dir = data_dir\n",
        "        self.classes = [\"real\", \"fake\"]\n",
        "        self.audio_files = []\n",
        "        self.labels = []\n",
        "        self.is_label = is_label\n",
        "        self.TARGET_SAMPLE_RATE =TARGET_SAMPLE_RATE\n",
        "        if self.is_label:\n",
        "            for class_idx, class_name in enumerate(self.classes):\n",
        "                class_dir = os.path.join(data_dir, class_name)\n",
        "                for file in os.listdir(class_dir):\n",
        "                    if file.endswith(\".mp3\"):\n",
        "                        self.audio_files.append(os.path.join(class_dir, file))\n",
        "                        self.labels.append(class_idx)\n",
        "        else:\n",
        "            for file in os.listdir(self.data_dir):\n",
        "                if file.endswith(\".mp3\"):\n",
        "                    self.audio_files.append(os.path.join(self.data_dir,file))\n",
        "\n",
        "        self.mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=TARGET_SAMPLE_RATE, n_fft=1024, hop_length=512, n_mels=64\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audio_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_file = self.audio_files[idx]\n",
        "        if self.is_label:\n",
        "            label = self.labels[idx]\n",
        "\n",
        "        # Load audio\n",
        "        audio, sr = torchaudio.load(audio_file)\n",
        "        # Convert to mono\n",
        "        if audio.shape[0] > 1:\n",
        "            audio = torch.mean(audio, dim=0).unsqueeze(0)\n",
        "\n",
        "        if sr != self.TARGET_SAMPLE_RATE:\n",
        "            audio = torchaudio.transforms.Resample(sr, self.TARGET_SAMPLE_RATE)(audio)\n",
        "\n",
        "        # Pad or truncate the audio to a fixed length\n",
        "        fixed_length = (\n",
        "            self.TARGET_SAMPLE_RATE * 3\n",
        "        )  # Adjust this value based on your requirements\n",
        "        if audio.shape[1] < fixed_length:\n",
        "            audio = torch.nn.functional.pad(audio, (0, fixed_length - audio.shape[1]))\n",
        "        else:\n",
        "            audio = audio[:, :fixed_length]\n",
        "\n",
        "        audio = self.mel_spectrogram(audio)\n",
        "        if self.is_label:\n",
        "            return audio, label\n",
        "        else:\n",
        "            #import for test generating\n",
        "            return audio, os.path.basename(audio_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1hzU65aDN2i"
      },
      "source": [
        "DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sz7JhFg8DN2j"
      },
      "outputs": [],
      "source": [
        "class Data:\n",
        "\n",
        "    def __init__(self, batch_size,dataset_train,dataset_test, do_split):\n",
        "        self.modes = ['train','test']\n",
        "        self.dataloaders = {}\n",
        "        self.batch_size = batch_size\n",
        "        self.do_split = do_split\n",
        "        if self.do_split:\n",
        "            self.modes = ['train','validation','test']\n",
        "            generator = torch.Generator().manual_seed(42)\n",
        "            train_size = int(len(dataset_train.audio_files)*0.8)\n",
        "            val_size = int(len(dataset_train.audio_files)-train_size)\n",
        "            train_set, val_set = random_split(dataset_train, [train_size, val_size], generator=generator)\n",
        "\n",
        "            self.dataloaders['train'] = train_set\n",
        "            self.dataloaders['validation'] = val_set\n",
        "        else:\n",
        "            self.dataloaders['train'] = dataset_train\n",
        "\n",
        "        self.dataloaders['test'] = dataset_test\n",
        "\n",
        "\n",
        "    def get_loader(self, mode):\n",
        "        if mode == 'train':\n",
        "            return  DataLoader(self.dataloaders[mode], batch_size=self.batch_size, shuffle=True)\n",
        "        else:\n",
        "            return  DataLoader(self.dataloaders[mode], batch_size=self.batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biLensleDN2j"
      },
      "source": [
        "Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tWvVocbODN2j"
      },
      "outputs": [],
      "source": [
        "class Evaluator:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.loss_fn = nn.BCELoss()\n",
        "    def get_loss(self, y, y_hat):\n",
        "        return self.loss_fn(y_hat, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSJ293AMDN2k"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q4zGqHCvHz-o"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.stride = stride\n",
        "\n",
        "        # Add a 1x1 convolution if the input channel size does not match the output channel size\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        else:\n",
        "            self.shortcut = nn.Sequential()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b4C6JtogH5al"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(16, 2)\n",
        "        self.layer2 = self.make_layer(32, 2, stride=2)\n",
        "        self.layer3 = self.make_layer(64, 2, stride=2)\n",
        "        self.layer4 = self.make_layer(128, 2, stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(128, 1)\n",
        "\n",
        "    def make_layer(self, out_channels, blocks, stride=1):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VZpdrrHcDN2l"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        dummy_tensor = self.conv_layer(torch.zeros(self.input_size).unsqueeze(0))\n",
        "        dim = 1\n",
        "        for d in dummy_tensor.shape[1:]:\n",
        "            dim *= d\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layer(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear_relu_stack(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrjPmuWyDN2l"
      },
      "source": [
        "Learner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1NmxTBveDN2m"
      },
      "outputs": [],
      "source": [
        "class Learner:\n",
        "    def __init__(self, input_size):\n",
        "        self.model = ResNet(input_size=input_size)\n",
        "        self.model.to(DEVICE)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def update(self, loss):\n",
        "        # Backpropagation\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABU48WoRDN2m"
      },
      "source": [
        "Metrics e best models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EqC8RrA8Lged"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "class Metrics2():\n",
        "    #FOR TRAIN AND VALIDATION ONLY\n",
        "    def __init__(self):\n",
        "        self.metrics_save = {}\n",
        "        self.best_models_weigths = {}\n",
        "        self.metrics_names  = ['accuracy', 'recall', 'precision', 'f1-score']\n",
        "\n",
        "    def calc_metrics(self, preds, labels, mode, loss, model_weights=None, show=False):\n",
        "        acc = accuracy_score(y_pred=preds, y_true=labels)\n",
        "        recall = recall_score(y_pred=preds, y_true=labels)\n",
        "        precision = precision_score(y_pred=preds, y_true=labels)\n",
        "        f1 = f1_score(y_pred=preds, y_true=labels, average='binary')\n",
        "        metrics_values = [acc, recall, precision, f1]\n",
        "\n",
        "        # Save loss\n",
        "        if f'{mode}_loss' not in self.metrics_save.keys():\n",
        "            self.metrics_save[f'{mode}_loss'] = [loss]\n",
        "        else:\n",
        "            self.metrics_save[f'{mode}_loss'].append(loss)\n",
        "\n",
        "        # Print metrics if show is True\n",
        "        if show:\n",
        "            print(f\"{mode.capitalize()} - Accuracy: {acc:.2f} - Recall: {recall:.2f} - Precision: {precision:.2f} - F1-Score: {f1:.2f} - Loss: {loss:.2f}\")\n",
        "\n",
        "        # Save metrics\n",
        "        for metric_name, metric_value in zip(self.metrics_names, metrics_values):\n",
        "            if f'{mode}_{metric_name}' not in self.metrics_save.keys():\n",
        "                self.metrics_save[f'{mode}_{metric_name}'] = [metric_value]\n",
        "            else:\n",
        "                self.metrics_save[f'{mode}_{metric_name}'].append(metric_value)\n",
        "\n",
        "            # Save best metrics and respective weights\n",
        "            if mode == 'train':\n",
        "                if f'{mode}_best_{metric_name}' not in self.metrics_save.keys():\n",
        "                    self.metrics_save[f'{mode}_best_{metric_name}'] = metric_value\n",
        "                    self.best_models_weigths[f'{mode}_best_{metric_name}'] = model_weights\n",
        "                elif metric_value > self.metrics_save[f'{mode}_best_{metric_name}']:\n",
        "                    self.metrics_save[f'{mode}_best_{metric_name}'] = metric_value\n",
        "                    self.best_models_weigths[f'{mode}_best_{metric_name}'] = model_weights\n",
        "\n",
        "    def plot_metrics(self, iteration):\n",
        "        fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
        "        metrics = self.metrics_names.copy()\n",
        "        modes = ['train', 'validation']\n",
        "        for i, metric_name in enumerate(metrics):\n",
        "            for mode in modes:\n",
        "                metric_values = self.metrics_save[f'{mode}_{metric_name}']\n",
        "                axs[i // 2, i % 2].plot(np.arange(iteration), metric_values, label=mode)\n",
        "\n",
        "                axs[i // 2, i % 2].set_title(f'{metric_name.capitalize()}: {modes[0]} x {modes[1]}')\n",
        "                axs[i // 2, i % 2].set_xlabel('Iteration')\n",
        "                axs[i // 2, i % 2].set_ylabel(metric_name.capitalize())\n",
        "                axs[i // 2, i % 2].legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_loss(self, iteration):\n",
        "        modes = ['train', 'validation']\n",
        "        metric_name = 'loss'\n",
        "        fig, axs = plt.subplots(1, 1, figsize=(6, 6))\n",
        "        for mode in modes:\n",
        "            metric_values = np.exp(self.metrics_save[f'{mode}_{metric_name}'])\n",
        "            axs.plot(np.arange(iteration), metric_values, label=mode)\n",
        "\n",
        "        axs.set_title(f'Log scale {metric_name.capitalize()}: {modes[0]} x {modes[1]}')\n",
        "        axs.set_xlabel('Iteration')\n",
        "        axs.set_ylabel(metric_name.capitalize())\n",
        "        axs.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def get_best_model(self, metric):\n",
        "        for key in self.best_models_weigths.keys():\n",
        "            if metric in key:\n",
        "                return self.best_models_weigths[key]\n",
        "\n",
        "    def save_best_model(self, all_metrics, metric='f1-score'):\n",
        "        if all_metrics:\n",
        "            print(\"Saving all models\")\n",
        "            for key in self.best_models_weigths.keys():\n",
        "                torch.save(f'{self.best_models_weigths[key]}.pt', key)\n",
        "                print(f\"Saved model at: {key}.pt\")\n",
        "\n",
        "        else:\n",
        "            print(f\"Saving best model for {metric}\")\n",
        "            for key in self.best_models_weigths.keys():\n",
        "                if metric in key:\n",
        "                    torch.save(f'{self.best_models_weigths[key]}.pt', key)\n",
        "                    print(f\"Saved model at: {key}.pt\")\n",
        "                    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oDof3shxDN2m"
      },
      "outputs": [],
      "source": [
        "class Metrics():\n",
        "    #FOR TRAIN AND VALIDATION ONLY\n",
        "    def __init__(self):\n",
        "        self.metrics_save = {}\n",
        "        self.best_models_weigths = {}\n",
        "        self.metrics_names  = ['acuracy','recall','precision','f1-score']\n",
        "\n",
        "    def calc_metrics(self,preds,labels,mode,loss, model_weigths=None, show=False):\n",
        "        acc = accuracy_score(y_pred=preds, y_true=labels)\n",
        "        recall = recall_score(y_pred=preds, y_true=labels)\n",
        "        precision = precision_score(y_pred=preds, y_true=labels)\n",
        "        f1 = f1_score(y_pred=preds, y_true=labels,average='binary')\n",
        "        metrics_values = [acc,recall,precision,f1]\n",
        "\n",
        "\n",
        "        ###################LOSS#############################################\n",
        "        if f'{mode}_loss' not in self.metrics_save.keys():\n",
        "            self.metrics_save[f'{mode}_loss'] = [loss]\n",
        "        else:\n",
        "            self.metrics_save[f'{mode}_loss'].append(loss)\n",
        "        ################################################################\n",
        "\n",
        "        if show:\n",
        "            print(f\"{mode} -  Acuracy: {acc:.2f} - Recall {recall:.2f} - Precision {precision:.2f} - F1-Score {f1:.2f} - Loss {loss:.2f}\")\n",
        "\n",
        "\n",
        "        #############Metrics##################################################\n",
        "\n",
        "        for metric_name, metric_value in zip(self.metrics_names, metrics_values):\n",
        "\n",
        "            ###Add metrics\n",
        "            if f'{mode}_{metric_name}' not in self.metrics_save.keys():\n",
        "                self.metrics_save[f'{mode}_{metric_name}'] = [metric_value]\n",
        "            else:\n",
        "                self.metrics_save[f'{mode}_{metric_name}'].append(metric_value)\n",
        "\n",
        "            ###Sava best metrics and respective weigths\n",
        "            if mode == 'train':\n",
        "                if f'{mode}_best_{metric_name}' not in self.metrics_save.keys():\n",
        "                    self.metrics_save[f'{mode}_best_{metric_name}'] = metric_value\n",
        "                    self.best_models_weigths[f'{mode}_best_{metric_name}'] = model_weigths\n",
        "                elif metric_value > self.metrics_save[f'{mode}_best_{metric_name}'] :\n",
        "                    self.best_models_weigths[f'{mode}_best_{metric_name}'] = model_weigths\n",
        "\n",
        "        ################################################################\n",
        "\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
        "        metrics = self.metrics_names.copy()\n",
        "        modes = ['train','validation']\n",
        "        for i,metric_name in enumerate(metrics):\n",
        "            metric_train  = self.metrics_save[f'{modes[0]}_{metric_name}']\n",
        "            metric_validation  = self.metrics_save[f'{modes[1]}_{metric_name}']\n",
        "\n",
        "            ii = i % 2\n",
        "            jj = i // 2\n",
        "            axs[jj,ii].plot(metric_train, label=modes[0])\n",
        "            axs[jj,ii].plot(metric_validation, label=modes[1])\n",
        "\n",
        "            axs[jj,ii].set_title(f'{metric_name}: {modes[0]} x {modes[1]}')\n",
        "            axs[jj,ii].set_xlabel('Epoch')\n",
        "            axs[jj,ii].set_ylabel(f'{metric_name}')\n",
        "            axs[jj,ii].legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Mostrar o plot\n",
        "        plt.show()\n",
        "\n",
        "    def plot_loss(self):\n",
        "        modes = ['train','validation']\n",
        "        metric_name = 'loss'\n",
        "        metric_train  = np.exp(self.metrics_save[f'{modes[0]}_{metric_name}'])\n",
        "        metric_validation  = np.exp(self.metrics_save[f'{modes[1]}_{metric_name}'])\n",
        "        fig, axs = plt.subplots(1, 1, figsize=(6, 12))\n",
        "        i = 0\n",
        "        axs[i,i].set_title(f'Log scale {metric_name}: {modes[0]} x {modes[1]}')\n",
        "        axs[i,i].plot(metric_train, label=modes[0])\n",
        "        axs[i,i].plot(metric_validation, label=modes[1])\n",
        "        axs[i,i].set_xlabel('Epoch')\n",
        "        axs[i,i].set_ylabel(f'{metric_name}')\n",
        "        axs[i,i].legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        # Mostrar o plot\n",
        "        plt.show()\n",
        "\n",
        "    def get_best_model(self, metric):\n",
        "        for key in self.best_models_weigths.keys():\n",
        "                if metric in key:\n",
        "                    return self.best_models_weigths[key]\n",
        "\n",
        "    def save_best_model(self,all_metrics, metric='F1-Score'):\n",
        "        if all_metrics:\n",
        "            print(\"Saving all models\")\n",
        "            for key in self.best_models_weigths.keys():\n",
        "                torch.save(f'{self.best_models_weigths[key]}.pt', key)\n",
        "                print(f\"Save model at: {key}.pt\")\n",
        "\n",
        "        else:\n",
        "            print(f\"Saving best model for {metric}\")\n",
        "            for key in self.best_models_weigths.keys():\n",
        "                if metric in key:\n",
        "                    torch.save(f'{self.best_models_weigths[key]}.pt', key)\n",
        "                    print(f\"Save model at: {key}.pt\")\n",
        "                    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z57d9js6DN2m"
      },
      "source": [
        "Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1crurCseDN2m"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, data: Data, learner: Learner, evaluator: Evaluator, metrics: Metrics):\n",
        "        self.data = data\n",
        "        self.learner = learner\n",
        "        self.metrics = metrics\n",
        "        self.evaluator = evaluator\n",
        "\n",
        "    def one_epoch(self, mode):\n",
        "        if mode == 'train':\n",
        "            self.learner.model.train(True)\n",
        "        else:\n",
        "            self.learner.model.train(False)\n",
        "\n",
        "\n",
        "        dataloader = self.data.get_loader(mode)\n",
        "        preds = []\n",
        "        labels = []\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for (X, y) in tqdm.tqdm(dataloader):\n",
        "            X, y = X.to(DEVICE), y.to(DEVICE).float().unsqueeze(1)\n",
        "\n",
        "            y_hat = self.learner.predict(X)\n",
        "\n",
        "            loss = self.evaluator.get_loss(y, y_hat)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            if mode == 'train':\n",
        "                self.learner.update(loss)\n",
        "\n",
        "            labels.extend(y.int().tolist())\n",
        "            preds.extend((y_hat > 0.5).int().tolist())\n",
        "\n",
        "        epoch_loss /= len(dataloader)\n",
        "\n",
        "        #preds,labels,mode,loss, model_weigths=None, show=False\n",
        "        self.metrics.calc_metrics(preds=preds, labels=labels, mode=mode, loss=epoch_loss, model_weigths=self.learner.model.state_dict(), show=True)\n",
        "\n",
        "    def test(self,mode,name_test, model_weigths=None):\n",
        "        self.learner.model.load_state_dict(model_weigths)\n",
        "        self.learner.model.train(False)\n",
        "        dataloader = self.data.get_loader(mode)\n",
        "        preds = []\n",
        "        ids = []\n",
        "        for (X, x_id) in tqdm.tqdm(dataloader):\n",
        "            X = X.to(DEVICE)\n",
        "            y_hat = self.learner.predict(X)\n",
        "            ids.extend(x_id)\n",
        "            preds.extend((y_hat).float().tolist())\n",
        "\n",
        "        file_test_submtion =  open(f'{name_test}.csv','w')\n",
        "        file_test_submtion.write('id,fake_prob\\n')\n",
        "        for idx,pred in zip(ids,preds):\n",
        "            file_test_submtion.write(f\"{idx},{pred[0]}\\n\")\n",
        "        print(f\"Test submission for {name_test} saved at {name_test}.csv\")\n",
        "\n",
        "\n",
        "    def run(self, n_epochs: int):\n",
        "        print(\"Starting training\")\n",
        "        for t in range(n_epochs):\n",
        "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "            self.one_epoch(mode='train')\n",
        "\n",
        "            with torch.no_grad():\n",
        "                self.one_epoch(mode='validation')\n",
        "        print(\"Training done\")\n",
        "\n",
        "    def run_test(self,name_test):\n",
        "        #Keep test at the end of training\n",
        "        metric = 'f1-score'\n",
        "        print(f\"Generating test probs with {metric} best model:\")\n",
        "        with torch.no_grad():\n",
        "            best_model = self.metrics.get_best_model(metric=metric)\n",
        "            self.test(mode='test', name_test=name_test, model_weigths=best_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0oiwkpwDN2n"
      },
      "source": [
        "Run training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAsDyEE3DN2n"
      },
      "source": [
        "instancias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obfjiyvPDN2n"
      },
      "outputs": [],
      "source": [
        "#datasets\n",
        "audio_train = AudioDataset(data_dir='/content/audios/train', is_label=True)\n",
        "audio_teste = AudioDataset(data_dir='/content/audios/test', is_label=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42k_PuSLDN2n"
      },
      "outputs": [],
      "source": [
        "#dataloaders\n",
        "data =Data(batch_size=100, dataset_train=audio_train, dataset_test=audio_teste, do_split=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foJ38YKCDN2n"
      },
      "outputs": [],
      "source": [
        "#evaluator\n",
        "evaluator = Evaluator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GME3sxd_DN2o"
      },
      "outputs": [],
      "source": [
        "#learner\n",
        "learner = Learner(input_size=(1,64,94))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpsoZgR4DN2o"
      },
      "outputs": [],
      "source": [
        "metrics = Metrics2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1bebNR5DN2o"
      },
      "source": [
        "Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JW3-xkgDN2o",
        "outputId": "84da6548-6821-464b-caeb-e0a65c50482f"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(data=data, evaluator=evaluator, learner=learner, metrics=metrics)\n",
        "trainer.run(n_epochs=10)\n",
        "trainer.run_test(name_test='test_cnn_baseline')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v_V22y8IDN2p",
        "outputId": "b698eb5d-d489-4626-f574-89a9328a7837"
      },
      "outputs": [],
      "source": [
        "metrics.plot_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjTvBWheDN2p"
      },
      "outputs": [],
      "source": [
        "metrics.plot_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSVSX7-ZDN2p",
        "outputId": "741744bb-3b52-4450-c6dc-19f317c51d3f"
      },
      "outputs": [],
      "source": [
        "#save all metrics\n",
        "metrics.save_best_model(all_metrics=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLHxhM7GDN2p",
        "outputId": "2526f3bd-ec0d-4cf3-95cf-f88f39777218"
      },
      "outputs": [],
      "source": [
        "#save only one metric\n",
        "metrics.save_best_model(all_metrics=False, metric='recall')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
